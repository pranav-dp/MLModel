{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652e92eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no mc\n",
      "ceph can not be used\n",
      "no mc\n",
      "no mc\n",
      "ceph can not be used\n",
      "no mc\n",
      "ceph can not be used\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "loader = yaml.SafeLoader\n",
    "loader.add_implicit_resolver(\n",
    "    u'tag:yaml.org,2002:float',\n",
    "    re.compile(u'''^(?:\n",
    "     [-+]?(?:[0-9][0-9_]*)\\\\.[0-9_]*(?:[eE][-+]?[0-9]+)?\n",
    "    |[-+]?(?:[0-9][0-9_]*)(?:[eE][-+]?[0-9]+)\n",
    "    |\\\\.[0-9_]+(?:[eE][-+][0-9]+)?\n",
    "    |[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\\\.[0-9_]*\n",
    "    |[-+]?\\\\.(?:inf|Inf|INF)\n",
    "    |\\\\.(?:nan|NaN|NAN))$''', re.X),\n",
    "    list(u'-+0123456789.'))\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from core.config import Config \n",
    "from core.testers import tester_entry \n",
    "# https://stackoverflow.com/questions/56395914/how-to-fix-error-while-loading-shared-libraries-libpython3-6m-so-1-0-cannot-o\n",
    "# https://stackoverflow.com/questions/71759248/importerror-cannot-import-name-builder-from-google-protobuf-internal\n",
    "from core import distributed_utils as dist\n",
    "from core.distributed_utils import dist_init\n",
    "from core.testers import tester_entry\n",
    "from core.data.datasets.images.parsing_dataset import Human3M6ParsingDataset\n",
    "import core.data.transforms.parsing_transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a387d36f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_palette(num_cls):\n",
    "    \"\"\" Returns the color map for visualizing the segmentation mask.\n",
    "    Args:\n",
    "        num_cls: Number of classes\n",
    "    Returns:\n",
    "        The color map\n",
    "    \"\"\"\n",
    "    n = num_cls\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return np.array(palette).reshape(-1,3)\n",
    "\n",
    "class InferenceParsingDataset(Human3M6ParsingDataset):\n",
    "    def __init__(self,\n",
    "             data_paths,\n",
    "             dataset='train',\n",
    "             is_train=True,\n",
    "             cfg=None,\n",
    "             **kwargs):\n",
    "        \"\"\"human3.6m dataset for human parsing\n",
    "        Args:\n",
    "            root_dir ([str]): where dataset\n",
    "            dataset: train / val\n",
    "            cfg: yaml format config\n",
    "        \"\"\"\n",
    "        # self.task_name = 'human3m6_parsing'\n",
    "        self.cfg = cfg\n",
    "        self.dataset = dataset\n",
    "        self.is_train = is_train\n",
    "\n",
    "        self.pseudo_labels = True\n",
    "\n",
    "        self.img_list = data_paths\n",
    "\n",
    "        self.images = self.img_list\n",
    "        self.ignore_label = cfg.ignore_value\n",
    "        self.num = len(self.images)\n",
    "        self.num_classes = len(self.cfg.label_list)  # - 1\n",
    "        assert self.num_classes == self.cfg.num_classes, f\"num of class mismatch, len(label_list)={self.num_classes}, num_classes:{self.cfg.num_classes}\"\n",
    "\n",
    "        self.rank = dist.get_rank()\n",
    "        self.world_size = dist.get_world_size()\n",
    "\n",
    "        self.original_label = np.array(self.cfg.label_list)\n",
    "\n",
    "        self.augs = T.compose([T.resize_image_eval(cfg.eval_crop_size),\n",
    "                              T.transpose()])\n",
    "        print(f\"-- Loading {dataset} dataset of {len(data_paths)} images\")\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        dataset_dict = {}\n",
    "        img_path = self.img_list[index]\n",
    "        dataset_dict[\"filename\"] = os.path.basename(img_path)\n",
    "        \n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        parsing_seg_gt = np.zeros_like(image)\n",
    "\n",
    "        self._record_image_size(dataset_dict, image)\n",
    "\n",
    "        if self.pseudo_labels:\n",
    "            image, parsing_seg_gt = self.augs(image, parsing_seg_gt)\n",
    "            image = torch.as_tensor(np.ascontiguousarray(image))\n",
    "            dataset_dict[\"image\"] = image\n",
    "            return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab476e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b0074c",
   "metadata": {},
   "source": [
    "# run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89df2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_initialize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd90bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 2\n",
    "\n",
    "# image_path = 'output/test_data/bikini_set/ou (6).png'\n",
    "# image_path = \"/media/hdd2/james/TryonTrainingImageProcessing/test_data/farfetch/tophalf_20266288_50422787_1000.jpg\"\n",
    "# data_paths = [image_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7689a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter from the test script\n",
    "which_model = \"CIHP\" # UniHCP finetuned on which dataset\n",
    "\n",
    "if which_model == \"Human3M6\":\n",
    "    TASK=\"par_lpe\"  # Human3M6ParsingDataset\n",
    "    GINFO_INDEX=\"1\"   # task index config cherrypick (if necessary)\n",
    "    save_name = \"UniHCP-Human3M6\"\n",
    "elif which_model == \"LIP\":\n",
    "    TASK=\"par_lip_lpe\"\n",
    "    GINFO_INDEX=\"3\"\n",
    "    save_name = \"UniHCP-LIP\"\n",
    "elif which_model == \"CIHP\":\n",
    "    TASK=\"par_cihp_lpe\"\n",
    "    GINFO_INDEX=\"4\"\n",
    "    save_name = \"UniHCP-CIHP\"\n",
    "    \"\"\"\n",
    "    map for CIHP:\n",
    "    {\n",
    "    1:'hat'\n",
    "    2:'hair',\n",
    "    4:'sunglasses',\n",
    "    5:'upperclothes',\n",
    "    6:'dress',\n",
    "    7:'coat',\n",
    "    9:'pants',\n",
    "    10:'torsoSkin',\n",
    "    12:'skirt',\n",
    "    13:'face',\n",
    "    14:'leftArm',\n",
    "    15:'rightArm',\n",
    "    16:'leftLeg',\n",
    "    17:'rightLeg',\n",
    "    18:'leftShoe',\n",
    "    19:'rightShoe'\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "elif which_model == \"DeepFashion\":\n",
    "    TASK=\"par_deepfashion_lpe\"\n",
    "    GINFO_INDEX=\"21\"\n",
    "    save_name = \"UniHCP-DeepFashion\"\n",
    "elif which_model == \"VIP\":\n",
    "    TASK=\"par_vip_lpe\"\n",
    "    GINFO_INDEX=\"22\"\n",
    "    save_name = \"UniHCP-VIP\"\n",
    "elif which_model == \"ModaNet\":\n",
    "    TASK=\"par_modanet_lpe\"\n",
    "    GINFO_INDEX=\"23\"\n",
    "    save_name = \"UniHCP-ModaNet\"\n",
    "else:\n",
    "    raise ValueError(\"Unknown model\")\n",
    "    \n",
    "################### ||| additional params usually not used\n",
    "job_name='coslr1e3_104k_b4324g88_h256_I2k_1_10_001_2I_fairscale_m256'  #${4-debug}\n",
    "CONFIG_BASE = \"experiments/unihcp/release\"\n",
    "PRETRAIN_JOB_NAME=job_name #${6-${job_name}}\n",
    "CONFIG=f\"{CONFIG_BASE}/{job_name}.yaml\"\n",
    "TEST_CONFIG=f\"{CONFIG_BASE}/vd_{TASK}_test.yaml\"\n",
    "TEST_MODEL=f\"checkpoints/{PRETRAIN_JOB_NAME}/ckpt_task{GINFO_INDEX}_iter_newest.pth.tar\"\n",
    "\n",
    "assert os.path.isfile(CONFIG)\n",
    "assert os.path.isfile(TEST_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea9c17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(auto_resume=None, config='experiments/unihcp/release/coslr1e3_104k_b4324g88_h256_I2k_1_10_001_2I_fairscale_m256.yaml', expname='test_par_cihp_lpe', ignore=[], load_path='checkpoints/coslr1e3_104k_b4324g88_h256_I2k_1_10_001_2I_fairscale_m256/ckpt_task4_iter_newest.pth.tar', load_single=False, recover=False, spec_ginfo_index=4, test_config='experiments/unihcp/release/vd_par_cihp_lpe_test.yaml')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    expname=f\"test_{TASK}\",\n",
    "    config=CONFIG,\n",
    "    test_config=TEST_CONFIG,\n",
    "    spec_ginfo_index=int(GINFO_INDEX),\n",
    "    load_path=TEST_MODEL,\n",
    "    load_single=False,\n",
    "    auto_resume=None,\n",
    "    recover=False,\n",
    "    ignore=[]\n",
    ")\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39972e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dist_initialize:\n",
    "    dist_init(gpu=gpu)\n",
    "    dist_initialize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111ee468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank 0] >> task_info.group[0] ranks [0]\n",
      "[rank 0] >> task_info.root_group ranks [0]\n",
      "[rank 0] >> task_info.backbone_share_group[[0]] ranks [0]\n",
      "[rank 0] >> task_info.neck_share_group[[0]] ranks [0]\n",
      "[rank 0] >> task_info.decoder_share_group[[0]] ranks [0]\n",
      "[rank 0] backbone of task0 has been overided to {'type': 'vit_base_patch16', 'kwargs': {'task_sp_list': ['rel_pos_h', 'rel_pos_w'], 'pretrained': True, 'lms_checkpoint_train': 'fairscale', 'window': False, 'test_pos_mode': 'learnable_interpolate', 'learnable_pos': True, 'drop_path_rate': 0.2, 'img_size': 1344}}\n",
      "[rank 0] decoder of task0 has been overided to {'type': 'AIOHead', 'kwargs': {'task': 'par_bce_cls_emb', 'task_sp_list': ['loss.', 'predictor.query_feat', 'predictor.query_embed'], 'loss_weight': 1.0, 'transformer_predictor_cfg': {'hidden_dim': 256, 'num_queries': 20, 'nheads': 8, 'dim_feedforward': 2048, 'dec_layers': 9, 'pre_norm': False, 'arch': 'fan_in', 'enforce_input_project': False, 'mask_on': False, 'num_feature_levels': 1, 'cross_pos_embed': 'anchor', 'cls_out_dim': 1}, 'loss_cfg': {'type': 'FocalDiceLoss_bce_cls_emb_sample_weight', 'kwargs': {'cfg': {'deep_supervision': True, 'no_object_weight': 0.1, 'class_weight': 0.25, 'dice_weight': 5.0, 'mask_weight': 5.0, 'redundant_queries': 1, 'num_points': 12544, 'dec_layers': 9, 'oversample_ratio': 3.0, 'importance_sample_ratio': 0.75, 'sample_weight': [1.0, 0.25279349, 0.97595474, 0.06368458, 0.08419378, 0.91287129, 0.18341584, 0.50346535, 0.12729844, 0.6937058, 0.96898868, 0.07022631, 0.07464639, 0.99359972, 0.88490099, 0.88490099, 0.27644979000000003, 0.27644979000000003, 0.33016266, 0.33016266]}}}}}\n",
      "[rank 0] dataset of task0 has been overided to {'type': 'CIHPParsingDataset', 'kwargs': {'data_path': '/mnt/path...to.../CIHP', 'cfg': {'is_flip': True, 'crop_size': [480, 480], 'is_multi_scale': True, 'scale_factor': 11, 'center_crop_test': False, 'base_size': 480, 'eval_crop_size': [480, 480], 'is_photometricdistortion': True, 'brightness': 32, 'contrast_range': [0.5, 1.5], 'saturation_range': [0.5, 1.5], 'hue_delta': 18, 'is_rotate': True, 'ignore_value': 255, 'num_classes': 20, 'label_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}}}\n",
      "[rank 0] sampler of task0 has been overided to {'batch_size': 54, 'shuffle_strategy': 1}\n",
      "----------------------\n",
      "[rank 0] >> task_info.group[0] ranks [0]\n",
      "[rank 0] >> task_info.root_group ranks [0]\n",
      "[rank 0] >> task_info.backbone_share_group[[0]] ranks [0]\n",
      "[rank 0] >> task_info.neck_share_group[[0]] ranks [0]\n",
      "[rank 0] >> task_info.decoder_share_group[[0]] ranks [0]\n",
      "[rank 0] dataset of task0 has been overided to {'type': 'CIHPParsingDataset', 'kwargs': {'data_path': '/mnt/path...to.../CIHP', 'dataset': 'val', 'is_train': False, 'cfg': {'eval_crop_size': [480, 480], 'is_flip': False, 'is_multi_scale': False, 'ignore_value': 255, 'num_classes': 20, 'label_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}}}\n",
      "[rank 0] sampler of task0 has been overided to {'batch_size': 16}\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "C_train = Config(args.config, spec_ginfo_index=args.spec_ginfo_index)\n",
    "print(\"----------------------\")\n",
    "\n",
    "with open(args.test_config) as f:\n",
    "    test_config = yaml.load(f, Loader=loader)\n",
    "num_test_tasks = len(test_config['tasks'])\n",
    "assert num_test_tasks == 1, \"One task/dataset\"\n",
    "\n",
    "test_spec_ginfo_index = 0\n",
    "C_test = Config(args.test_config, spec_ginfo_index=test_spec_ginfo_index)\n",
    "if args.expname is not None:\n",
    "    C_train.config['expname'] = args.expname\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac08976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sync_print: rank 0, override tensor.cuda() to preserve task_specific flag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-21 13:37:41,680][solver_multitask_dev.py][line: 661][    INFO] deterministic mode, seed: 233, worker_rank: True,                                   cudnn_deterministic: False\n",
      "INFO:global_logger:deterministic mode, seed: 233, worker_rank: True,                                   cudnn_deterministic: False\n"
     ]
    }
   ],
   "source": [
    "# load manager\n",
    "S = tester_entry(C_train, C_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85d8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1d65f4d",
   "metadata": {},
   "source": [
    "## Select image dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c76d89b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to ip_data/results/UniHCP-CIHP/test_sample\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"ip_data/test_data/test_sample\"\n",
    "# image_dir = \"ip_data/test_data/ssense\"\n",
    "# image_dir = \"ip_data/test_data/farfetch\"\n",
    "# image_dir = \"ip_data/test_data/wild\"\n",
    "\n",
    "save_raw = False\n",
    "# save_raw = True\n",
    "\n",
    "data_paths = [os.path.join(image_dir, img_fn) for img_fn in os.listdir(image_dir) \n",
    "              if os.path.splitext(img_fn)[1] in [\".jpg\", \".png\", \".jpeg\"]]\n",
    "test_set_name = os.path.basename(image_dir)\n",
    "if not save_raw:\n",
    "    save_dir = f\"ip_data/results/{save_name}/{test_set_name}\"\n",
    "else:\n",
    "    save_dir = f\"ip_data/results/{save_name}/{test_set_name}_raw\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(\"Save to\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78157b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Loading val dataset of 2 images\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "S.config.dataset.kwargs.ginfo = S.ginfo\n",
    "S.dataset = InferenceParsingDataset(data_paths=data_paths, **S.config.dataset[\"kwargs\"])\n",
    "dist.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e6b0178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank 0] Position interpolate from (14, 14) to (84, 84)\n",
      "Missing keys: []\n",
      "\n",
      "finish load\n",
      "sync_print: rank 0, Number of conv/bn params: 0.59M\n",
      "sync_print: rank 0, Number of linear params: 85.02M\n",
      "aio_entry_v2(\n",
      "  (backbone_module): ViT(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.0181818176060915)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.036363635212183)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.05454545468091965)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.072727270424366)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.09090908616781235)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.10909091681241989)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.12727272510528564)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.1454545557498932)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.16363637149333954)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.1818181872367859)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (drop_path): DropPath(p=0.20000000298023224)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_pre): Identity()\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (neck_module): SimpleNeck(\n",
      "    (mask_map): Sequential(\n",
      "      (0): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): Norm2d(\n",
      "        (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): GELU()\n",
      "      (3): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (decoder_module): AIOHead(\n",
      "    (predictor): TransformerDecoder(\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 128\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "      (transformer_self_attention_layers): ModuleList(\n",
      "        (0): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (2): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (3): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (4): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (5): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (6): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (7): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (8): SelfAttentionLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (transformer_cross_attention_layers): ModuleList(\n",
      "        (0): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (2): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (3): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (4): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (5): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (6): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (7): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (8): CrossAttentionLayer(\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (transformer_ffn_layers): ModuleList(\n",
      "        (0): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): FFNLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (query_feat): Embedding(20, 256)\n",
      "      (query_embed): Embedding(20, 256)\n",
      "      (level_embed): Embedding(1, 256)\n",
      "      (input_proj): ModuleList(\n",
      "        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (class_embed): Linear(in_features=256, out_features=1, bias=True)\n",
      "      (mask_embed): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (adapt_pos2d): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (loss): FocalDiceLoss_bce_cls_emb_sample_weight(\n",
      "      (fd_loss): Criterion SetCriterion\n",
      "          matcher: Matcher DirectMatcher\n",
      "              cost_class: 1\n",
      "              cost_mask: 1\n",
      "              cost_dice: 1\n",
      "          losses: ['bce_labels', 'masks']\n",
      "          weight_dict: {'loss_bce': 0.25, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_bce_0': 0.25, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_bce_1': 0.25, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_bce_2': 0.25, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_bce_3': 0.25, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_bce_4': 0.25, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_bce_5': 0.25, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_bce_6': 0.25, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_bce_7': 0.25, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_bce_8': 0.25, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}\n",
      "          num_classes: 20\n",
      "          eos_coef: 0.1\n",
      "          num_points: 12544\n",
      "          oversample_ratio: 3.0\n",
      "          importance_sample_ratio: 0.75\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.pos_embed\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.patch_embed.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.0.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.1.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.2.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.3.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.4.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.5.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.6.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.7.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.8.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.9.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.10.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.norm1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.qkv.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.attn.proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.norm2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.blocks.11.mlp.fc2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.backbone_module.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.neck_module.mask_map.0.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.neck_module.mask_map.0.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.neck_module.mask_map.1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.neck_module.mask_map.1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.neck_module.mask_map.3.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting backbone-specific param module.neck_module.mask_map.3.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377228>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.0.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.0.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.0.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.0.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.1.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.1.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.1.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.1.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.2.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.2.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.2.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.2.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.3.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.3.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.3.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.3.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.4.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.4.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.4.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.4.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.5.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.5.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.5.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.5.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.6.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.6.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.6.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.6.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.7.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.7.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.7.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.7.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.8.self_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.8.self_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.8.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_self_attention_layers.8.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.0.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.0.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.1.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.1.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.2.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.2.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.3.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.3.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.4.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.4.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.5.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.5.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.6.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.6.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.7.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.7.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.8.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_cross_attention_layers.8.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.0.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.0.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.0.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.0.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.0.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.0.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.1.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.1.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.1.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.1.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.1.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.1.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.2.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.2.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.2.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.2.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.2.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.2.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.3.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.3.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.3.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.3.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.3.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.3.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.4.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.4.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.4.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.4.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.4.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.4.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.5.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.5.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.5.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.5.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.5.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.5.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.6.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.6.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.6.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.6.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.6.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.6.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.7.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.7.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.7.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.7.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.7.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.7.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.8.linear1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.8.linear1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.8.linear2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.8.linear2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.8.norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.transformer_ffn_layers.8.norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.decoder_norm.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.decoder_norm.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting task-specific param module.decoder_module.predictor.query_feat.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377148>\n",
      "[rank 0] broadcasting task-specific param module.decoder_module.predictor.query_embed.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377148>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.level_embed.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.input_proj.0.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.input_proj.0.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.class_embed.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.class_embed.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.mask_embed.layers.0.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.mask_embed.layers.0.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.mask_embed.layers.1.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.mask_embed.layers.1.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.mask_embed.layers.2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.mask_embed.layers.2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.adapt_pos2d.0.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.adapt_pos2d.0.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.adapt_pos2d.2.weight\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting decoder-specific param module.decoder_module.predictor.adapt_pos2d.2.bias\tgroup=<torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f03c8377538>\n",
      "[rank 0] broadcasting task-specific buffer module.decoder_module.loss.fd_loss.empty_weight\n",
      "-- Load checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank 0] Recovering from checkpoints/coslr1e3_104k_b4324g88_h256_I2k_1_10_001_2I_fairscale_m256/ckpt_task4_iter_newest.pth.tar, keys=['step', 'state_dict', 'optimizer']\n",
      "[rank 0] ======= loading model state for task 0 ... =======\n",
      "[rank 0] load msg: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "S.create_model()\n",
    "print(\"-- Load checkpoint\")\n",
    "S.load_args = args\n",
    "S.load(args);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77cc542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to ip_data/results/UniHCP-CIHP/test_sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "S.create_dataloader()\n",
    "palette = get_palette(S.dataset.num_classes)\n",
    "\n",
    "S.model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, S.tmp.input in tqdm(enumerate(S.test_loader), total=len(S.test_loader)):\n",
    "        S.prepare_data()\n",
    "        outputs = S.model(S.tmp.input_var, idx)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        for i, output in enumerate(outputs):\n",
    "            par_pred = output[\"sem_seg\"]\n",
    "            output = par_pred.argmax(dim=0).cpu()\n",
    "            pred = np.array(output, dtype=np.int)\n",
    "            img_name = S.tmp.input_var[\"filename\"][i]\n",
    "            save_path = os.path.join(save_dir, os.path.splitext(img_name)[0]+\"-.png\")\n",
    "            if save_raw:\n",
    "                cv2.imwrite(save_path, pred)\n",
    "            else:\n",
    "#                 cv2.imwrite(save_path, palette[pred])\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(palette[pred].astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
    "print(\"Save to\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6891b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99fa4c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1334, 1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_pred = outputs[0][\"sem_seg\"]\n",
    "output = par_pred.argmax(dim=0).cpu()\n",
    "pred = np.array(output, dtype=np.int)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf97194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 480, 480])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.tmp.input_var[\"image\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09b1c6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21d2cf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  6,  8, 10, 13, 14, 15, 18, 19])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fbe9091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = os.path.join(image_dir, S.tmp.input_var[\"filename\"][0])\n",
    "plt.imshow(plt.imread(img_path))\n",
    "plt.show()\n",
    "plt.imshow(palette[pred])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b5597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "338.823517px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
